{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fb08b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from recsys_utils import *\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787be75d",
   "metadata": {},
   "source": [
    "# Import our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d96249f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%Incorrect</th>\n",
       "      <th>Heart of Algebra</th>\n",
       "      <th>Passport to Advanced Math</th>\n",
       "      <th>Problem Solving and Data Analysis</th>\n",
       "      <th>Additional Topics</th>\n",
       "      <th>MC</th>\n",
       "      <th>SA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.337851</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483508</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.549151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.509471</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.605813</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.483721</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.037209</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.283721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.479070</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0.502326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     %Incorrect  Heart of Algebra  Passport to Advanced Math  \\\n",
       "0      0.337851                 1                          0   \n",
       "1      0.483508                 1                          0   \n",
       "2      0.549151                 1                          0   \n",
       "3      0.509471                 0                          1   \n",
       "4      0.605813                 1                          0   \n",
       "..          ...               ...                        ...   \n",
       "633    0.483721                 0                          1   \n",
       "634    0.037209                 1                          0   \n",
       "635    0.283721                 0                          0   \n",
       "636    0.479070                 0                          1   \n",
       "637    0.502326                 0                          1   \n",
       "\n",
       "     Problem Solving and Data Analysis  Additional Topics  MC  SA  \n",
       "0                                    0                  0   1   0  \n",
       "1                                    0                  0   1   0  \n",
       "2                                    0                  0   1   0  \n",
       "3                                    0                  0   1   0  \n",
       "4                                    0                  0   1   0  \n",
       "..                                 ...                ...  ..  ..  \n",
       "633                                  0                  0   0   1  \n",
       "634                                  0                  0   0   1  \n",
       "635                                  0                  1   0   1  \n",
       "636                                  0                  0   0   1  \n",
       "637                                  0                  0   0   1  \n",
       "\n",
       "[638 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import questions features\n",
    "\n",
    "file_path1 = 'df_question_features.csv'\n",
    "df_question_features = pd.read_csv(file_path1)\n",
    "df_question_features.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df_question_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a950a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import student features\n",
    "\n",
    "file_path1 = 'df_student_features.csv'\n",
    "file_path2 = 'df_Y.csv'\n",
    "df_student_features = pd.read_csv(file_path1) #(rows=students, columns=performance metric) \n",
    "df_YY = pd.read_csv(file_path2) #(rows=question, columns=student) Student answers for each question, NaN for unanswared questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a747464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID_0</th>\n",
       "      <th>Student_ID_1</th>\n",
       "      <th>Student_ID_2</th>\n",
       "      <th>Student_ID_3</th>\n",
       "      <th>Student_ID_4</th>\n",
       "      <th>Student_ID_5</th>\n",
       "      <th>Student_ID_6</th>\n",
       "      <th>Student_ID_7</th>\n",
       "      <th>Student_ID_8</th>\n",
       "      <th>Student_ID_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Student_ID_10079</th>\n",
       "      <th>Student_ID_10080</th>\n",
       "      <th>Student_ID_10081</th>\n",
       "      <th>Student_ID_10082</th>\n",
       "      <th>Student_ID_10083</th>\n",
       "      <th>Student_ID_10084</th>\n",
       "      <th>Student_ID_10085</th>\n",
       "      <th>Student_ID_10086</th>\n",
       "      <th>Student_ID_10087</th>\n",
       "      <th>Student_ID_10088</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 10089 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Student_ID_0  Student_ID_1  Student_ID_2  Student_ID_3  Student_ID_4  \\\n",
       "0             0.0           0.0           1.0           NaN           1.0   \n",
       "1             0.0           0.0           0.0           NaN           0.0   \n",
       "2             0.0           0.0           1.0           NaN           0.0   \n",
       "3             0.0           1.0           1.0           NaN           1.0   \n",
       "4             1.0           1.0           1.0           NaN           1.0   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "633           NaN           NaN           NaN           NaN           NaN   \n",
       "634           NaN           NaN           NaN           NaN           NaN   \n",
       "635           NaN           NaN           NaN           NaN           NaN   \n",
       "636           NaN           NaN           NaN           NaN           NaN   \n",
       "637           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "     Student_ID_5  Student_ID_6  Student_ID_7  Student_ID_8  Student_ID_9  \\\n",
       "0             0.0           0.0           0.0           NaN           NaN   \n",
       "1             0.0           0.0           0.0           NaN           NaN   \n",
       "2             0.0           0.0           0.0           NaN           NaN   \n",
       "3             0.0           0.0           0.0           NaN           NaN   \n",
       "4             0.0           0.0           0.0           NaN           NaN   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "633           NaN           NaN           NaN           NaN           0.0   \n",
       "634           NaN           NaN           NaN           NaN           0.0   \n",
       "635           NaN           NaN           NaN           NaN           0.0   \n",
       "636           NaN           NaN           NaN           NaN           0.0   \n",
       "637           NaN           NaN           NaN           NaN           0.0   \n",
       "\n",
       "     ...  Student_ID_10079  Student_ID_10080  Student_ID_10081  \\\n",
       "0    ...               NaN               NaN               NaN   \n",
       "1    ...               NaN               NaN               NaN   \n",
       "2    ...               NaN               NaN               NaN   \n",
       "3    ...               NaN               NaN               NaN   \n",
       "4    ...               NaN               NaN               NaN   \n",
       "..   ...               ...               ...               ...   \n",
       "633  ...               NaN               NaN               NaN   \n",
       "634  ...               NaN               NaN               NaN   \n",
       "635  ...               NaN               NaN               NaN   \n",
       "636  ...               NaN               NaN               NaN   \n",
       "637  ...               NaN               NaN               NaN   \n",
       "\n",
       "     Student_ID_10082  Student_ID_10083  Student_ID_10084  Student_ID_10085  \\\n",
       "0                 NaN               1.0               NaN               0.0   \n",
       "1                 NaN               0.0               NaN               1.0   \n",
       "2                 NaN               1.0               NaN               0.0   \n",
       "3                 NaN               1.0               NaN               1.0   \n",
       "4                 NaN               0.0               NaN               0.0   \n",
       "..                ...               ...               ...               ...   \n",
       "633               NaN               NaN               NaN               NaN   \n",
       "634               NaN               NaN               NaN               NaN   \n",
       "635               NaN               NaN               NaN               NaN   \n",
       "636               NaN               NaN               NaN               NaN   \n",
       "637               NaN               NaN               NaN               NaN   \n",
       "\n",
       "     Student_ID_10086  Student_ID_10087  Student_ID_10088  \n",
       "0                 1.0               NaN               0.0  \n",
       "1                 1.0               NaN               1.0  \n",
       "2                 1.0               NaN               0.0  \n",
       "3                 1.0               NaN               1.0  \n",
       "4                 1.0               NaN               1.0  \n",
       "..                ...               ...               ...  \n",
       "633               NaN               NaN               NaN  \n",
       "634               NaN               NaN               NaN  \n",
       "635               NaN               NaN               NaN  \n",
       "636               NaN               NaN               NaN  \n",
       "637               NaN               NaN               NaN  \n",
       "\n",
       "[638 rows x 10089 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0be0773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level 1</th>\n",
       "      <th>Level 2</th>\n",
       "      <th>Level 3</th>\n",
       "      <th>Level 4</th>\n",
       "      <th>Level 5</th>\n",
       "      <th>Word Problems</th>\n",
       "      <th>Multiple-Choice</th>\n",
       "      <th>Grid-In</th>\n",
       "      <th>One-Variable Linear Equations</th>\n",
       "      <th>Linear Functions</th>\n",
       "      <th>...</th>\n",
       "      <th>Equivalent Expressions</th>\n",
       "      <th>One-Variable Nonlinear Equations and Two-Variable Systems</th>\n",
       "      <th>Nonlinear Functions</th>\n",
       "      <th>Area and Volume</th>\n",
       "      <th>Lines, Angles, and Triangles</th>\n",
       "      <th>Right Triangles and Trigonometry</th>\n",
       "      <th>Circles</th>\n",
       "      <th>Complex Numbers</th>\n",
       "      <th>Math_Score</th>\n",
       "      <th>English_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>52.333333</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>43.666667</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>72.333333</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>36.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>493.333333</td>\n",
       "      <td>650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.200000</td>\n",
       "      <td>52.200000</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>15.6</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>38.400000</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>63.200000</td>\n",
       "      <td>63.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>34.6</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.333333</td>\n",
       "      <td>57.333333</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>44.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>463.333333</td>\n",
       "      <td>546.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>74.200000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>53.4</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>52.600000</td>\n",
       "      <td>66.800000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>83.400000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.600000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>702.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>58.400000</td>\n",
       "      <td>49.800000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>48.800000</td>\n",
       "      <td>52.400000</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>70.200000</td>\n",
       "      <td>66.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>31.2</td>\n",
       "      <td>33.800000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>648.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10084</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10085</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>410.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>590.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10088</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10089 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Level 1    Level 2    Level 3  Level 4    Level 5  Word Problems  \\\n",
       "0       60.000000  65.333333  52.333333     38.0   5.666667      43.666667   \n",
       "1       62.200000  52.200000  29.200000     15.6  14.800000      31.600000   \n",
       "2       64.333333  57.333333  48.000000     25.0  14.333333      37.000000   \n",
       "3       90.000000  74.200000  55.000000     53.4  25.400000      52.600000   \n",
       "4       66.000000  58.400000  49.800000     23.0  15.200000      48.800000   \n",
       "...           ...        ...        ...      ...        ...            ...   \n",
       "10084  100.000000  63.000000  46.000000     25.0  57.000000      46.000000   \n",
       "10085   80.000000  85.000000  54.000000     36.0   0.000000      52.000000   \n",
       "10086   60.000000  15.000000  25.000000      0.0   0.000000      28.000000   \n",
       "10087   33.000000  63.000000  29.000000     38.0  14.000000      42.000000   \n",
       "10088   40.000000  38.000000  29.000000      0.0   0.000000      28.000000   \n",
       "\n",
       "       Multiple-Choice    Grid-In  One-Variable Linear Equations  \\\n",
       "0            55.333333  17.666667                      72.333333   \n",
       "1            38.400000  12.400000                      63.200000   \n",
       "2            44.333333  33.333333                      27.666667   \n",
       "3            66.800000  27.800000                      83.400000   \n",
       "4            52.400000  15.200000                      70.200000   \n",
       "...                ...        ...                            ...   \n",
       "10084        51.000000  31.000000                      50.000000   \n",
       "10085        62.000000  31.000000                     100.000000   \n",
       "10086        24.000000   0.000000                       0.000000   \n",
       "10087        42.000000   8.000000                      50.000000   \n",
       "10088        31.000000   0.000000                      50.000000   \n",
       "\n",
       "       Linear Functions  ...  Equivalent Expressions  \\\n",
       "0             55.666667  ...               56.666667   \n",
       "1             63.400000  ...               33.000000   \n",
       "2            100.000000  ...               65.000000   \n",
       "3             37.500000  ...               80.000000   \n",
       "4             66.600000  ...               35.000000   \n",
       "...                 ...  ...                     ...   \n",
       "10084        100.000000  ...               60.000000   \n",
       "10085        100.000000  ...               50.000000   \n",
       "10086         33.000000  ...                0.000000   \n",
       "10087        100.000000  ...               20.000000   \n",
       "10088         33.000000  ...               50.000000   \n",
       "\n",
       "       One-Variable Nonlinear Equations and Two-Variable Systems  \\\n",
       "0                                                   36.0           \n",
       "1                                                   34.6           \n",
       "2                                                   26.0           \n",
       "3                                                   57.0           \n",
       "4                                                   31.2           \n",
       "...                                                  ...           \n",
       "10084                                               40.0           \n",
       "10085                                               38.0           \n",
       "10086                                               13.0           \n",
       "10087                                               20.0           \n",
       "10088                                               13.0           \n",
       "\n",
       "       Nonlinear Functions  Area and Volume  Lines, Angles, and Triangles  \\\n",
       "0                26.000000         6.666667                     75.000000   \n",
       "1                25.400000        20.000000                     33.333333   \n",
       "2                32.666667         0.000000                      0.000000   \n",
       "3                58.600000        42.000000                     50.000000   \n",
       "4                33.800000         4.000000                     50.000000   \n",
       "...                    ...              ...                           ...   \n",
       "10084            20.000000        40.000000                           NaN   \n",
       "10085            25.000000         0.000000                    100.000000   \n",
       "10086            50.000000         0.000000                      0.000000   \n",
       "10087             0.000000        40.000000                           NaN   \n",
       "10088            25.000000         0.000000                      0.000000   \n",
       "\n",
       "       Right Triangles and Trigonometry    Circles  Complex Numbers  \\\n",
       "0                                  50.0  16.666667        33.333333   \n",
       "1                                  20.0  10.000000        40.000000   \n",
       "2                                  50.0  16.666667        33.333333   \n",
       "3                                  80.0  10.000000        20.000000   \n",
       "4                                  30.0  10.000000         0.000000   \n",
       "...                                 ...        ...              ...   \n",
       "10084                               0.0  50.000000       100.000000   \n",
       "10085                             100.0   0.000000         0.000000   \n",
       "10086                              50.0   0.000000         0.000000   \n",
       "10087                              50.0   0.000000         0.000000   \n",
       "10088                               0.0   0.000000         0.000000   \n",
       "\n",
       "       Math_Score  English_Score  \n",
       "0      493.333333     650.000000  \n",
       "1      408.000000     550.000000  \n",
       "2      463.333333     546.666667  \n",
       "3      556.000000     702.000000  \n",
       "4      476.000000     648.000000  \n",
       "...           ...            ...  \n",
       "10084  490.000000     540.000000  \n",
       "10085  540.000000     600.000000  \n",
       "10086  330.000000     410.000000  \n",
       "10087  420.000000     590.000000  \n",
       "10088  360.000000     400.000000  \n",
       "\n",
       "[10089 rows x 30 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_student_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8971e6",
   "metadata": {},
   "source": [
    "# Data Pre-roccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a58e8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y = df_YY.fillna(2) # Fill in N/A values with 2 (this number is abritrary\n",
    "df_R = df_YY.notna().astype(int) # Fill in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0f8a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_features = df_student_features.fillna(-1) # Fill in N/A values with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98e0734e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (638, 10089) R (638, 10089)\n",
      "X1 (10089, 30)\n",
      "X2 (638, 7)\n",
      "num_student_features: 30\n",
      "num_question_features: 7\n",
      "num_questions: 638\n",
      "num_students: 10089\n"
     ]
    }
   ],
   "source": [
    "scaler_q = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_s = MinMaxScaler()\n",
    "\n",
    "\n",
    "student_features = df_student_features.values\n",
    "question_features = df_question_features.values\n",
    "\n",
    "\n",
    "student_features_scaled = scaler_s.fit_transform(student_features)\n",
    "question_features_scaled = scaler_q.fit_transform(question_features)\n",
    "\n",
    "\n",
    "#Load data\n",
    "Y = df_Y.values\n",
    "R = df_R.values\n",
    "\n",
    "\n",
    "X1 = student_features_scaled\n",
    "X2 = question_features_scaled\n",
    "\n",
    "\n",
    "num_student_features = X1.shape[1]\n",
    "num_question_features = X2.shape[1]\n",
    "num_questions = X2.shape[0]\n",
    "num_students = Y.shape[1]\n",
    "\n",
    "\n",
    "print(\"Y\", Y.shape, \"R\", R.shape)\n",
    "print(\"X1\", X1.shape)\n",
    "print(\"X2\", X2.shape)\n",
    "\n",
    "\n",
    "print(\"num_student_features:\", num_student_features)\n",
    "print(\"num_question_features:\", num_question_features)\n",
    "print(\"num_questions:\",   num_questions)\n",
    "print(\"num_students:\",    num_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b4803d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da7a581b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c45ef",
   "metadata": {},
   "source": [
    "# Lets build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e61d996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define function for changing model parameters quickly\n",
    "def initialize_neural_network(input_shape, num_layers, num_units, output_dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(Dense(num_units, input_shape=input_shape, activation='relu'))\n",
    "    \n",
    "    # Hidden layers\n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(output_dim, activation='linear'))  # Linear activation so that we can have negative outputs\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you want 3 hidden layers with 100 units each and an output dimension of 100\n",
    "num_layers = 3\n",
    "num_units = 20\n",
    "output_dim = 150\n",
    "\n",
    "# Initialize models\n",
    "# The output dimension of out two models will have to be the same so that we can take a dot product of the two in the loss step\n",
    "model_student_features = initialize_neural_network((num_student_features,), num_layers, num_units, output_dim)\n",
    "model_question_features = initialize_neural_network((num_question_features,), num_layers, num_units, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9060dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "# Loss will take the output from our model and perform a dot product operation on the two output vectors\n",
    "def custom_loss(X_1, X_2, Y, R, model_1, model_2):\n",
    "    \n",
    "    output_1 = model_1(X_1)\n",
    "\n",
    "    output_2 = model_2(X_2)\n",
    "    \n",
    "    output_1_transposed = tf.transpose(output_1) # To allow for matrix multiplication\n",
    "    \n",
    "    result = tf.matmul(output_2, output_1_transposed)\n",
    "    \n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=result) # Sigmoid Binary crossentropy loss function\n",
    "\n",
    "    # Take the transpose of the result\n",
    "    masked_cross_entropy = cross_entropy * R  # Apply mask R\n",
    "\n",
    "    J = tf.reduce_sum(masked_cross_entropy)        \n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4272a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast our data as tensors\n",
    "\n",
    "Y = tf.cast(Y, dtype=tf.float32)\n",
    "R = tf.cast(R, dtype=tf.float32)\n",
    "X1 = tf.cast(X1, dtype=tf.float32)\n",
    "X2 = tf.cast(X2, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f134e40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 839804.4\n",
      "Training loss at iteration 1: 833110.9\n",
      "Training loss at iteration 2: 826942.5\n",
      "Training loss at iteration 3: 821165.0\n",
      "Training loss at iteration 4: 815659.2\n",
      "Training loss at iteration 5: 810337.4\n",
      "Training loss at iteration 6: 805144.6\n",
      "Training loss at iteration 7: 800060.1\n",
      "Training loss at iteration 8: 795085.1\n",
      "Training loss at iteration 9: 790235.7\n",
      "Training loss at iteration 10: 785538.3\n",
      "Training loss at iteration 11: 781036.2\n",
      "Training loss at iteration 12: 776786.6\n",
      "Training loss at iteration 13: 772847.8\n",
      "Training loss at iteration 14: 769286.9\n",
      "Training loss at iteration 15: 766169.4\n",
      "Training loss at iteration 16: 763541.4\n",
      "Training loss at iteration 17: 761419.5\n",
      "Training loss at iteration 18: 759785.3\n",
      "Training loss at iteration 19: 758578.1\n",
      "Training loss at iteration 20: 757692.6\n",
      "Training loss at iteration 21: 756987.4\n",
      "Training loss at iteration 22: 756313.9\n",
      "Training loss at iteration 23: 755540.6\n",
      "Training loss at iteration 24: 754572.2\n",
      "Training loss at iteration 25: 753371.2\n",
      "Training loss at iteration 26: 751943.2\n",
      "Training loss at iteration 27: 750325.8\n",
      "Training loss at iteration 28: 748575.8\n",
      "Training loss at iteration 29: 746767.6\n",
      "Training loss at iteration 30: 744966.7\n",
      "Training loss at iteration 31: 743222.4\n",
      "Training loss at iteration 32: 741564.1\n",
      "Training loss at iteration 33: 740007.8\n",
      "Training loss at iteration 34: 738547.0\n",
      "Training loss at iteration 35: 737161.5\n",
      "Training loss at iteration 36: 735815.9\n",
      "Training loss at iteration 37: 734476.1\n",
      "Training loss at iteration 38: 733107.8\n",
      "Training loss at iteration 39: 731681.1\n",
      "Training loss at iteration 40: 730160.9\n",
      "Training loss at iteration 41: 728536.6\n",
      "Training loss at iteration 42: 726805.8\n",
      "Training loss at iteration 43: 724975.9\n",
      "Training loss at iteration 44: 723081.3\n",
      "Training loss at iteration 45: 721138.9\n",
      "Training loss at iteration 46: 719181.6\n",
      "Training loss at iteration 47: 717201.2\n",
      "Training loss at iteration 48: 715198.8\n",
      "Training loss at iteration 49: 713178.7\n",
      "Training loss at iteration 50: 711136.0\n",
      "Training loss at iteration 51: 709068.1\n",
      "Training loss at iteration 52: 706981.9\n",
      "Training loss at iteration 53: 704898.7\n",
      "Training loss at iteration 54: 702830.9\n",
      "Training loss at iteration 55: 700798.7\n",
      "Training loss at iteration 56: 698806.1\n",
      "Training loss at iteration 57: 696844.4\n",
      "Training loss at iteration 58: 694879.1\n",
      "Training loss at iteration 59: 692890.7\n",
      "Training loss at iteration 60: 690884.8\n",
      "Training loss at iteration 61: 688896.2\n",
      "Training loss at iteration 62: 686938.6\n",
      "Training loss at iteration 63: 684995.8\n",
      "Training loss at iteration 64: 683054.2\n",
      "Training loss at iteration 65: 681108.1\n",
      "Training loss at iteration 66: 679138.4\n",
      "Training loss at iteration 67: 677173.6\n",
      "Training loss at iteration 68: 675219.6\n",
      "Training loss at iteration 69: 673253.6\n",
      "Training loss at iteration 70: 671266.9\n",
      "Training loss at iteration 71: 669243.6\n",
      "Training loss at iteration 72: 667201.4\n",
      "Training loss at iteration 73: 665156.2\n",
      "Training loss at iteration 74: 663098.6\n",
      "Training loss at iteration 75: 661015.7\n",
      "Training loss at iteration 76: 658909.1\n",
      "Training loss at iteration 77: 656781.0\n",
      "Training loss at iteration 78: 654638.9\n",
      "Training loss at iteration 79: 652484.6\n",
      "Training loss at iteration 80: 650336.8\n",
      "Training loss at iteration 81: 648192.5\n",
      "Training loss at iteration 82: 646018.4\n",
      "Training loss at iteration 83: 643817.5\n",
      "Training loss at iteration 84: 641651.5\n",
      "Training loss at iteration 85: 639498.9\n",
      "Training loss at iteration 86: 637345.6\n",
      "Training loss at iteration 87: 635200.7\n",
      "Training loss at iteration 88: 633102.8\n",
      "Training loss at iteration 89: 631048.6\n",
      "Training loss at iteration 90: 629040.6\n",
      "Training loss at iteration 91: 627079.2\n",
      "Training loss at iteration 92: 625182.8\n",
      "Training loss at iteration 93: 623365.4\n",
      "Training loss at iteration 94: 621599.3\n",
      "Training loss at iteration 95: 619909.6\n",
      "Training loss at iteration 96: 618299.4\n",
      "Training loss at iteration 97: 616785.7\n",
      "Training loss at iteration 98: 615342.0\n",
      "Training loss at iteration 99: 614006.5\n",
      "Training loss at iteration 100: 612796.2\n",
      "Training loss at iteration 101: 611743.8\n",
      "Training loss at iteration 102: 610890.1\n",
      "Training loss at iteration 103: 610265.3\n",
      "Training loss at iteration 104: 609883.1\n",
      "Training loss at iteration 105: 609679.9\n",
      "Training loss at iteration 106: 609615.1\n",
      "Training loss at iteration 107: 609639.1\n",
      "Training loss at iteration 108: 609661.8\n",
      "Training loss at iteration 109: 609627.7\n",
      "Training loss at iteration 110: 609519.6\n",
      "Training loss at iteration 111: 609625.7\n",
      "Training loss at iteration 112: 610114.1\n",
      "Training loss at iteration 113: 611157.4\n",
      "Training loss at iteration 114: 612576.2\n",
      "Training loss at iteration 115: 614116.9\n",
      "Training loss at iteration 116: 615688.9\n",
      "Training loss at iteration 117: 617307.8\n",
      "Training loss at iteration 118: 618855.8\n",
      "Training loss at iteration 119: 620586.3\n",
      "Training loss at iteration 120: 622706.4\n",
      "Training loss at iteration 121: 625069.5\n",
      "Training loss at iteration 122: 627763.2\n",
      "Training loss at iteration 123: 630818.1\n",
      "Training loss at iteration 124: 634135.8\n",
      "Training loss at iteration 125: 637513.1\n",
      "Training loss at iteration 126: 640862.9\n",
      "Training loss at iteration 127: 644122.4\n",
      "Training loss at iteration 128: 647208.0\n",
      "Training loss at iteration 129: 650023.9\n",
      "Training loss at iteration 130: 652756.4\n",
      "Training loss at iteration 131: 655402.7\n",
      "Training loss at iteration 132: 657977.2\n",
      "Training loss at iteration 133: 660445.7\n",
      "Training loss at iteration 134: 662771.9\n",
      "Training loss at iteration 135: 664914.4\n",
      "Training loss at iteration 136: 666875.3\n",
      "Training loss at iteration 137: 668738.4\n",
      "Training loss at iteration 138: 670533.6\n",
      "Training loss at iteration 139: 672315.7\n",
      "Training loss at iteration 140: 674025.0\n",
      "Training loss at iteration 141: 675554.5\n",
      "Training loss at iteration 142: 676671.8\n",
      "Training loss at iteration 143: 677320.2\n",
      "Training loss at iteration 144: 677574.1\n",
      "Training loss at iteration 145: 677616.1\n",
      "Training loss at iteration 146: 677563.7\n",
      "Training loss at iteration 147: 677691.3\n",
      "Training loss at iteration 148: 677883.8\n",
      "Training loss at iteration 149: 677854.8\n",
      "Training loss at iteration 150: 677392.6\n",
      "Training loss at iteration 151: 675293.9\n",
      "Training loss at iteration 152: 672164.9\n",
      "Training loss at iteration 153: 669175.6\n",
      "Training loss at iteration 154: 666737.2\n",
      "Training loss at iteration 155: 664842.1\n",
      "Training loss at iteration 156: 663453.9\n",
      "Training loss at iteration 157: 662231.1\n",
      "Training loss at iteration 158: 660875.3\n",
      "Training loss at iteration 159: 659338.9\n",
      "Training loss at iteration 160: 657727.5\n",
      "Training loss at iteration 161: 656162.1\n",
      "Training loss at iteration 162: 654740.9\n",
      "Training loss at iteration 163: 653523.7\n",
      "Training loss at iteration 164: 652701.9\n",
      "Training loss at iteration 165: 652397.1\n",
      "Training loss at iteration 166: 652663.7\n",
      "Training loss at iteration 167: 653266.8\n",
      "Training loss at iteration 168: 653950.3\n",
      "Training loss at iteration 169: 654582.6\n",
      "Training loss at iteration 170: 655150.2\n",
      "Training loss at iteration 171: 655775.3\n",
      "Training loss at iteration 172: 656458.0\n",
      "Training loss at iteration 173: 657140.8\n",
      "Training loss at iteration 174: 657655.1\n",
      "Training loss at iteration 175: 657862.1\n",
      "Training loss at iteration 176: 657617.3\n",
      "Training loss at iteration 177: 656915.1\n",
      "Training loss at iteration 178: 655867.4\n",
      "Training loss at iteration 179: 654617.4\n",
      "Training loss at iteration 180: 653267.1\n",
      "Training loss at iteration 181: 651853.1\n",
      "Training loss at iteration 182: 650386.4\n",
      "Training loss at iteration 183: 648845.1\n",
      "Training loss at iteration 184: 647205.3\n",
      "Training loss at iteration 185: 645506.9\n",
      "Training loss at iteration 186: 643795.6\n",
      "Training loss at iteration 187: 642120.2\n",
      "Training loss at iteration 188: 640515.6\n",
      "Training loss at iteration 189: 638946.2\n",
      "Training loss at iteration 190: 637396.2\n",
      "Training loss at iteration 191: 635863.1\n",
      "Training loss at iteration 192: 634362.6\n",
      "Training loss at iteration 193: 632930.9\n",
      "Training loss at iteration 194: 631594.6\n",
      "Training loss at iteration 195: 630366.2\n",
      "Training loss at iteration 196: 629265.5\n",
      "Training loss at iteration 197: 628316.8\n",
      "Training loss at iteration 198: 627503.8\n",
      "Training loss at iteration 199: 626819.8\n",
      "Training loss at iteration 200: 626249.1\n",
      "Training loss at iteration 201: 625760.8\n",
      "Training loss at iteration 202: 625339.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 203: 624994.1\n",
      "Training loss at iteration 204: 624736.8\n",
      "Training loss at iteration 205: 624570.0\n",
      "Training loss at iteration 206: 624501.8\n",
      "Training loss at iteration 207: 624555.7\n",
      "Training loss at iteration 208: 624725.1\n",
      "Training loss at iteration 209: 624973.6\n",
      "Training loss at iteration 210: 625256.6\n",
      "Training loss at iteration 211: 625524.9\n",
      "Training loss at iteration 212: 625765.1\n",
      "Training loss at iteration 213: 625958.6\n",
      "Training loss at iteration 214: 626097.3\n",
      "Training loss at iteration 215: 626169.5\n",
      "Training loss at iteration 216: 626190.4\n",
      "Training loss at iteration 217: 626173.1\n",
      "Training loss at iteration 218: 626140.4\n",
      "Training loss at iteration 219: 626112.1\n",
      "Training loss at iteration 220: 626107.7\n",
      "Training loss at iteration 221: 626132.1\n",
      "Training loss at iteration 222: 626184.1\n",
      "Training loss at iteration 223: 626273.8\n",
      "Training loss at iteration 224: 626421.1\n",
      "Training loss at iteration 225: 626643.8\n",
      "Training loss at iteration 226: 626977.4\n",
      "Training loss at iteration 227: 627422.9\n",
      "Training loss at iteration 228: 627957.2\n",
      "Training loss at iteration 229: 628570.0\n",
      "Training loss at iteration 230: 629235.2\n",
      "Training loss at iteration 231: 629912.4\n",
      "Training loss at iteration 232: 630597.9\n",
      "Training loss at iteration 233: 631268.9\n",
      "Training loss at iteration 234: 631906.8\n",
      "Training loss at iteration 235: 632497.1\n",
      "Training loss at iteration 236: 633025.9\n",
      "Training loss at iteration 237: 633501.8\n",
      "Training loss at iteration 238: 633944.8\n",
      "Training loss at iteration 239: 634368.9\n",
      "Training loss at iteration 240: 634770.5\n",
      "Training loss at iteration 241: 635158.0\n",
      "Training loss at iteration 242: 635521.8\n",
      "Training loss at iteration 243: 635856.9\n",
      "Training loss at iteration 244: 636149.8\n",
      "Training loss at iteration 245: 636389.2\n",
      "Training loss at iteration 246: 636561.3\n",
      "Training loss at iteration 247: 636657.8\n",
      "Training loss at iteration 248: 636685.9\n",
      "Training loss at iteration 249: 636670.0\n",
      "Training loss at iteration 250: 636644.4\n",
      "Training loss at iteration 251: 636618.1\n",
      "Training loss at iteration 252: 636611.6\n",
      "Training loss at iteration 253: 636628.1\n",
      "Training loss at iteration 254: 636653.5\n",
      "Training loss at iteration 255: 636691.3\n",
      "Training loss at iteration 256: 636719.6\n",
      "Training loss at iteration 257: 636733.8\n",
      "Training loss at iteration 258: 636745.1\n",
      "Training loss at iteration 259: 636643.6\n",
      "Training loss at iteration 260: 636364.6\n",
      "Training loss at iteration 261: 635872.6\n",
      "Training loss at iteration 262: 635224.3\n",
      "Training loss at iteration 263: 634470.5\n",
      "Training loss at iteration 264: 633625.5\n",
      "Training loss at iteration 265: 632691.3\n",
      "Training loss at iteration 266: 631657.2\n",
      "Training loss at iteration 267: 630534.6\n",
      "Training loss at iteration 268: 629360.4\n",
      "Training loss at iteration 269: 628136.4\n",
      "Training loss at iteration 270: 626891.2\n",
      "Training loss at iteration 271: 625626.0\n",
      "Training loss at iteration 272: 624359.8\n",
      "Training loss at iteration 273: 623119.8\n",
      "Training loss at iteration 274: 621937.9\n",
      "Training loss at iteration 275: 620841.8\n",
      "Training loss at iteration 276: 619829.7\n",
      "Training loss at iteration 277: 618905.5\n",
      "Training loss at iteration 278: 618061.6\n",
      "Training loss at iteration 279: 617303.2\n",
      "Training loss at iteration 280: 616615.4\n",
      "Training loss at iteration 281: 616006.3\n",
      "Training loss at iteration 282: 615452.0\n",
      "Training loss at iteration 283: 614951.2\n",
      "Training loss at iteration 284: 614494.0\n",
      "Training loss at iteration 285: 614082.1\n",
      "Training loss at iteration 286: 613724.5\n",
      "Training loss at iteration 287: 613402.7\n",
      "Training loss at iteration 288: 613108.6\n",
      "Training loss at iteration 289: 612822.6\n",
      "Training loss at iteration 290: 612518.7\n",
      "Training loss at iteration 291: 612173.8\n",
      "Training loss at iteration 292: 611782.3\n",
      "Training loss at iteration 293: 611356.8\n",
      "Training loss at iteration 294: 610919.8\n",
      "Training loss at iteration 295: 610474.4\n",
      "Training loss at iteration 296: 610017.6\n",
      "Training loss at iteration 297: 609545.2\n",
      "Training loss at iteration 298: 609053.4\n",
      "Training loss at iteration 299: 608551.9\n",
      "Training loss at iteration 300: 608044.7\n",
      "Training loss at iteration 301: 607543.4\n",
      "Training loss at iteration 302: 607035.7\n",
      "Training loss at iteration 303: 606520.6\n",
      "Training loss at iteration 304: 606008.0\n",
      "Training loss at iteration 305: 605500.2\n",
      "Training loss at iteration 306: 605004.2\n",
      "Training loss at iteration 307: 604513.6\n",
      "Training loss at iteration 308: 604029.1\n",
      "Training loss at iteration 309: 603550.5\n",
      "Training loss at iteration 310: 603076.5\n",
      "Training loss at iteration 311: 602610.5\n",
      "Training loss at iteration 312: 602154.8\n",
      "Training loss at iteration 313: 601708.4\n",
      "Training loss at iteration 314: 601278.7\n",
      "Training loss at iteration 315: 600864.4\n",
      "Training loss at iteration 316: 600473.8\n",
      "Training loss at iteration 317: 600111.8\n",
      "Training loss at iteration 318: 599772.7\n",
      "Training loss at iteration 319: 599456.7\n",
      "Training loss at iteration 320: 599165.0\n",
      "Training loss at iteration 321: 598913.3\n",
      "Training loss at iteration 322: 598728.8\n",
      "Training loss at iteration 323: 598600.8\n",
      "Training loss at iteration 324: 598552.9\n",
      "Training loss at iteration 325: 598598.4\n",
      "Training loss at iteration 326: 598773.9\n",
      "Training loss at iteration 327: 599105.9\n",
      "Training loss at iteration 328: 599626.2\n",
      "Training loss at iteration 329: 600330.8\n",
      "Training loss at iteration 330: 601219.4\n",
      "Training loss at iteration 331: 602333.2\n",
      "Training loss at iteration 332: 603614.5\n",
      "Training loss at iteration 333: 605075.9\n",
      "Training loss at iteration 334: 606623.4\n",
      "Training loss at iteration 335: 608252.8\n",
      "Training loss at iteration 336: 609929.9\n",
      "Training loss at iteration 337: 611683.2\n",
      "Training loss at iteration 338: 613521.1\n",
      "Training loss at iteration 339: 615448.5\n",
      "Training loss at iteration 340: 617400.6\n",
      "Training loss at iteration 341: 619427.9\n",
      "Training loss at iteration 342: 621475.3\n",
      "Training loss at iteration 343: 623177.8\n",
      "Training loss at iteration 344: 624207.9\n",
      "Training loss at iteration 345: 624289.3\n",
      "Training loss at iteration 346: 623608.6\n",
      "Training loss at iteration 347: 622402.2\n",
      "Training loss at iteration 348: 620952.1\n",
      "Training loss at iteration 349: 619344.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize Hyperparameters\n",
    "iterations = 350\n",
    "learning_rate = 0.0005\n",
    "lambda_ = 1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "epsilon = 1e-7\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer1 = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta1, beta_2=beta2, epsilon=epsilon)\n",
    "optimizer2 = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta1, beta_2=beta2, epsilon=epsilon )\n",
    "\n",
    "\n",
    "for iter in range(iterations):\n",
    "    # Use TensorFlow’s GradientTape\n",
    "    # Compute and apply Gradients for each model seperately\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute the cost (forward pass included in cost)\n",
    "        cost_value = custom_loss(X1, X2, Y, R, model_student_features, model_question_features) # compute cost\n",
    "    grads1 = tape.gradient(cost_value, model_student_features.trainable_variables) # Calculate gradients\n",
    "    optimizer1.apply_gradients(zip(grads1, model_student_features.trainable_variables)) # Apply gradients\n",
    "    \n",
    "    del tape # delete tape to insure not interference\n",
    "    \n",
    "    with tf.GradientTape() as tape2:\n",
    "        cost_value = custom_loss(X1, X2, Y, R, model_student_features, model_question_features)\n",
    "    grads2 = tape2.gradient(cost_value, model_question_features.trainable_variables)\n",
    "    optimizer2.apply_gradients(zip(grads2, model_question_features.trainable_variables))\n",
    "\n",
    "    \n",
    "    # Log periodically.\n",
    "    if iter % 1 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1768fcd6",
   "metadata": {},
   "source": [
    "# Evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "303b6907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 907202\n",
      "Accuracy: 0.7481424304349475\n"
     ]
    }
   ],
   "source": [
    "output_1 = model_student_features(X1)\n",
    "output_2 = model_question_features(X2)\n",
    "output_1_transposed = tf.transpose(output_1)\n",
    "result = tf.matmul(output_2, output_1_transposed)\n",
    "predict = tf.nn.sigmoid(result)\n",
    "\n",
    "# Set a threshold value\n",
    "threshold = 0.5\n",
    "\n",
    "# Apply the threshold to convert values to 0 or 1\n",
    "binary_array = np.where(predict >= threshold, 1, 0)\n",
    "\n",
    "# Create a DataFrame from the binary array\n",
    "df_binary = pd.DataFrame(binary_array)\n",
    "\n",
    "# Set the index and columns of df_Y to match df_binary\n",
    "df_Y.index = df_binary.index\n",
    "df_Y.columns = df_binary.columns\n",
    "\n",
    "# Count the number of matches\n",
    "matches = (df_binary == df_Y).sum().sum()\n",
    "\n",
    "excluded_count = (df_Y == 2).sum().sum()\n",
    "\n",
    "p = matches/((num_questions*num_students) - excluded_count)\n",
    "\n",
    "# Display the number of matches\n",
    "print(\"Number of matches:\", matches)\n",
    "print(\"Accuracy:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062bccab",
   "metadata": {},
   "source": [
    "# Making Reccomendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474181f2",
   "metadata": {},
   "source": [
    "<a name=\"5.3\"></a>\n",
    "### 5.3 - Finding Similar Items\n",
    "The neural network above produces two feature vectors, a student feature vector , and a question feature vector. The dimensions of each vector are difficult to interpret. However, if students have perform simmilary they will have similar vectors, likewise if questions have a similar level of difficulty, they will also have similar vectors. This information can be used to make recommendations. \n",
    "\n",
    "A similarity measure is the squared distance between the two vectors $ \\mathbf{v_m^{(k)}}$ and $\\mathbf{v_m^{(i)}}$ :\n",
    "$$\\left\\Vert \\mathbf{v_m^{(k)}} - \\mathbf{v_m^{(i)}}  \\right\\Vert^2 = \\sum_{l=1}^{n}(v_{m_l}^{(k)} - v_{m_l}^{(i)})^2\\tag{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5e777fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sq_dist(a,b):\n",
    "    \"\"\"\n",
    "    Returns the squared distance between two vectors\n",
    "    Args:\n",
    "      a (ndarray (n,)): vector with n features\n",
    "      b (ndarray (n,)): vector with n features\n",
    "    Returns:\n",
    "      d (float) : distance\n",
    "    \"\"\"     \n",
    "    d = np.sum(np.square(a - b))\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "73acc063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dist_matrix(output):\n",
    "    \n",
    "    output2 = np.array(output_2)\n",
    "    dist_matrix = np.zeros((output2.shape[0],output2.shape[0]))\n",
    "    for i in range(output2.shape[0]):\n",
    "        for j in range(output2.shape[0]):\n",
    "            distance = sq_dist(output2[i,:],output2[j,:])\n",
    "            dist_matrix[i,j] = distance\n",
    "            \n",
    "    return dist_matrix\n",
    "\n",
    "student_similarity_matrix = create_dist_matrix(output_1)\n",
    "question_similarity_matrix = create_dist_matrix(output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e94e6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similarities(similarity_matrix,id_):\n",
    "    \n",
    "    if similarity_matrix.shape[0] == 638:\n",
    "        column = f'Question_{id_}'\n",
    "    else:\n",
    "        column = f'Student_{id_}'\n",
    "    dfs = pd.DataFrame(similarity_matrix[:,id_], columns=[column])\n",
    "    dfs.index = range(1, len(dfs) + 1)\n",
    "    dfs = dfs.sort_values(by=[column], ascending=True)\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "870e5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_similaritites = find_similarities(student_similarity_matrix,5)\n",
    "question_similaritites = find_similarities(question_similarity_matrix,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2719c2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>2.389278e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1.327307e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2.113110e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>6.839908e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.935230e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.964635e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2.076416e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2.238847e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2.356166e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Question_5\n",
       "6    0.000000e+00\n",
       "469  2.389278e-07\n",
       "481  1.327307e-05\n",
       "127  2.113110e-05\n",
       "351  6.839908e-05\n",
       "..            ...\n",
       "173  1.935230e+00\n",
       "170  1.964635e+00\n",
       "289  2.076416e+00\n",
       "232  2.238847e+00\n",
       "174  2.356166e+00\n",
       "\n",
       "[638 rows x 1 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_similaritites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bb53285a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>2.133002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>2.133998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2.169678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>2.293292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2.303682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Question_90\n",
       "91      0.000000\n",
       "47      0.000030\n",
       "218     0.000588\n",
       "264     0.000839\n",
       "159     0.000873\n",
       "..           ...\n",
       "625     2.133002\n",
       "436     2.133998\n",
       "379     2.169678\n",
       "441     2.293292\n",
       "384     2.303682\n",
       "\n",
       "[638 rows x 1 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_similaritites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a699c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
